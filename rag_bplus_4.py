import tempfile
import os
import streamlit as st
from concurrent.futures import ThreadPoolExecutor
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredPowerPointLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from rouge_score import rouge_scorer
from langdetect import detect_langs

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë²¼ë½ì¹˜ê¸° ë„ìš°ë¯¸",
    page_icon="â³",
)

# Streamlit ì•± ì„¤ì •
def main():
    st.title("â³ ëŒ€í•™ìƒ ë²¼ë½ì¹˜ê¸° ë„ìš°ë¯¸")

    # ìƒíƒœ ì´ˆê¸°í™”
    if "uploaded_text" not in st.session_state:
        st.session_state.uploaded_text = None
    if "summary" not in st.session_state:
        st.session_state.summary = None
    if "roadmap" not in st.session_state:
        st.session_state.roadmap = None
    if "quiz" not in st.session_state:
        st.session_state.quiz = None

    with st.sidebar:
        uploaded_files = st.file_uploader("ğŸ“„ ê°•ì˜ ìë£Œ ì—…ë¡œë“œ", type=["pdf", "docx", "pptx"], accept_multiple_files=True)
        openai_api_key = st.text_input("ğŸ”‘ OpenAI API í‚¤", type="password")
        process_button = st.button("ğŸš€ ë²¼ë½ì¹˜ê¸° ì‹œì‘í•˜ê¸°")

        create_summary = st.checkbox("í•µì‹¬ ìš”ì•½ ìƒì„±", value=True)
        create_roadmap = st.checkbox("ê³µë¶€ ë¡œë“œë§µ ìƒì„±", value=True)
        create_quiz = st.checkbox("ì˜ˆìƒ ë¬¸ì œ ìƒì„±", value=True)
        show_metrics = st.checkbox("ìš”ì•½ ì„±ëŠ¥ í‰ê°€ í‘œì‹œ", value=True)

    if process_button:
        if not openai_api_key:
            st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        if not uploaded_files:
            st.warning("ê°•ì˜ ìë£Œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            return

        st.session_state.uploaded_text = extract_text_from_files(uploaded_files)
        text_chunks = split_text_into_chunks(st.session_state.uploaded_text)
        llm = ChatOpenAI(openai_api_key=openai_api_key, model_name="gpt-4")

        if create_summary:
            st.session_state.summary = summarize_text(text_chunks, llm)

        if create_roadmap and st.session_state.summary:
            st.session_state.roadmap = create_study_roadmap(st.session_state.summary, llm, 7)

        if create_quiz and st.session_state.summary:
            st.session_state.quiz = generate_quiz_questions(st.session_state.summary, llm)

        if show_metrics and st.session_state.summary:
            st.subheader("ğŸ“Š ìš”ì•½ ì„±ëŠ¥ í‰ê°€")
            metrics = evaluate_summary(st.session_state.uploaded_text, st.session_state.summary)
            for metric, score in metrics.items():
                st.write(f"**{metric}:** {score:.2f}")

    if st.session_state.summary:
        st.subheader("ğŸ“Œ í•µì‹¬ ìš”ì•½")
        st.markdown(st.session_state.summary)

    if st.session_state.roadmap:
        st.subheader("ğŸ“‹ ê³µë¶€ ë¡œë“œë§µ")
        st.markdown(st.session_state.roadmap)

    if st.session_state.quiz:
        st.subheader("â“ ì˜ˆìƒ ë¬¸ì œ")
        st.markdown(st.session_state.quiz)

# í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_text_from_files(files):
    doc_list = []
    for file in files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".tmp") as tmp_file:
            tmp_file.write(file.read())
            temp_file_path = tmp_file.name

        if file.name.endswith(".pdf"):
            loader = PyPDFLoader(temp_file_path)
        elif file.name.endswith(".docx"):
            loader = Docx2txtLoader(temp_file_path)
        elif file.name.endswith(".pptx"):
            loader = UnstructuredPowerPointLoader(temp_file_path)
        else:
            st.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file.name}")
            continue

        documents = loader.load_and_split()
        doc_list.extend(documents)

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(temp_file_path)
    return doc_list

# ë³‘ë ¬ ì²˜ë¦¬ëœ ìš”ì•½ë¬¸ í›„ì²˜ë¦¬ í•¨ìˆ˜
def refine_summary(summaries, llm):
    combined_summary = "\n".join(summaries)
    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ìš”ì•½ë¬¸ì„ ì •ë¦¬í•˜ê³  ê°„ê²°í•˜ê²Œ ë§Œë“œëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."),
        HumanMessage(content=f"ë‹¤ìŒ ìš”ì•½ë¬¸ë“¤ì„ ì½ê³  í•˜ë‚˜ì˜ ì¼ê´€ëœ ìš”ì•½ë¬¸ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:\n\n{combined_summary}")
    ]
    response = llm(messages)
    return response.content

# í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• 
def split_text_into_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,
        chunk_overlap=300
    )
    return text_splitter.split_documents(text)

if __name__ == "__main__":
    main()
