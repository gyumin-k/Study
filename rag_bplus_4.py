import tempfile
import os
import streamlit as st
from concurrent.futures import ThreadPoolExecutor
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredPowerPointLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage, Document
from datetime import datetime

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë²¼ë½ì¹˜ê¸° ë„ìš°ë¯¸", page_icon="â³")

# íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_file(file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=file.name) as tmp_file:
        tmp_file.write(file.read())
        temp_file_path = tmp_file.name

    if file.name.endswith(".pdf"):
        loader = PyPDFLoader(temp_file_path)
    elif file.name.endswith(".docx"):
        loader = Docx2txtLoader(temp_file_path)
    elif file.name.endswith(".pptx"):
        loader = UnstructuredPowerPointLoader(temp_file_path)
    else:
        st.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file.name}")
        return ""

    documents = loader.load_and_split()
    full_text = " ".join([doc.page_content for doc in documents])

    os.remove(temp_file_path)
    return full_text

# í…ìŠ¤íŠ¸ ìš”ì•½
def summarize_text(text, llm, max_summary_length=2000):
    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ í•œêµ­ì–´ ìš”ì•½ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."),
        HumanMessage(content=f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{text}")
    ]
    response = llm(messages)
    return response.content[:max_summary_length] + "..." if len(response.content) > max_summary_length else response.content

# ê¸°ì¶œë¬¸ì œ í˜•ì‹ ì¶”ì¶œ
def extract_exam_format(text, llm):
    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ í•œêµ­ ëŒ€í•™ìƒì„ ìœ„í•œ ë¬¸ì œì§€ í˜•ì‹ ë¶„ì„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."),
        HumanMessage(content=f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì œì§€ì˜ í˜•ì‹ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        {text}
        í˜•ì‹ì ì¸ êµ¬ì¡°(ê°ê´€ì‹/ì£¼ê´€ì‹ ì—¬ë¶€, ë³´ê¸° í˜•ì‹ ë“±)ì— ì§‘ì¤‘í•´ì£¼ì„¸ìš”.
        """)
    ]
    response = llm(messages)
    return response.content

# ì˜ˆìƒ ë¬¸ì œ ìƒì„±
def generate_quiz_questions(text, exam_format, llm):
    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ í•œêµ­ ëŒ€í•™ìƒì„ ìœ„í•œ ì˜ˆìƒ ë¬¸ì œë¥¼ ì‘ì„±í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."),
        HumanMessage(content=f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆìƒ ë¬¸ì œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
        {text}
        ë¬¸ì œì˜ í˜•ì‹ì€ ë‹¤ìŒì— ë§ì¶°ì£¼ì„¸ìš”:
        {exam_format}
        """)
    ]
    response = llm(messages)
    return response.content

# Streamlit ì•±
def main():
    st.title("â³ ëŒ€í•™ìƒ ë²¼ë½ì¹˜ê¸° ë„ìš°ë¯¸")

    if "lecture_text" not in st.session_state:
        st.session_state.lecture_text = {}

    if "exam_format" not in st.session_state:
        st.session_state.exam_format = None

    if "summary" not in st.session_state:
        st.session_state.summary = None

    if "quiz" not in st.session_state:
        st.session_state.quiz = None

    with st.sidebar:
        lecture_files = st.file_uploader("ğŸ“„ ê°•ì˜ìë£Œ ì—…ë¡œë“œ", type=["pdf", "docx", "pptx"], accept_multiple_files=True)
        exam_files = st.file_uploader("ğŸ“„ ê¸°ì¶œë¬¸ì œ ì—…ë¡œë“œ (í˜•ì‹ë§Œ ì‚¬ìš©)", type=["pdf", "docx", "pptx"], accept_multiple_files=True)
        openai_api_key = st.text_input("ğŸ”‘ OpenAI API í‚¤", type="password")
        process_button = st.button("ğŸš€ ì˜ˆìƒ ë¬¸ì œ ìƒì„±")

    if process_button:
        if not openai_api_key:
            st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return

        if not lecture_files:
            st.warning("ê°•ì˜ìë£Œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            return

        llm = ChatOpenAI(openai_api_key=openai_api_key, model_name="gpt-4")

        # ê°•ì˜ìë£Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ìš”ì•½
        for file in lecture_files:
            st.session_state.lecture_text[file.name] = extract_text_from_file(file)

        lecture_text = "\n".join(st.session_state.lecture_text.values())
        st.session_state.summary = summarize_text(lecture_text, llm)

        # ê¸°ì¶œë¬¸ì œ í˜•ì‹ ì¶”ì¶œ
        if exam_files:
            exam_text = "\n".join([extract_text_from_file(file) for file in exam_files])
            st.session_state.exam_format = extract_exam_format(exam_text, llm)
        else:
            st.session_state.exam_format = "ê°ê´€ì‹ê³¼ ì£¼ê´€ì‹ ë¬¸ì œë¡œ êµ¬ì„±ëœ ì¼ë°˜ì ì¸ ë¬¸ì œì§€ í˜•ì‹"

        # ì˜ˆìƒ ë¬¸ì œ ìƒì„±
        st.session_state.quiz = generate_quiz_questions(
            st.session_state.summary,
            st.session_state.exam_format,
            llm
        )

    # ê²°ê³¼ ì¶œë ¥
    if st.session_state.summary:
        st.subheader("ğŸ“Œ ìš”ì•½")
        st.markdown(st.session_state.summary)

    if st.session_state.exam_format:
        st.subheader("ğŸ“‹ ê¸°ì¶œë¬¸ì œ í˜•ì‹")
        st.markdown(st.session_state.exam_format)

    if st.session_state.quiz:
        st.subheader("â“ ì˜ˆìƒ ë¬¸ì œ")
        st.markdown(st.session_state.quiz)

if __name__ == "__main__":
    main()
