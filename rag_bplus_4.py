import tempfile
import os
import streamlit as st
from concurrent.futures import ThreadPoolExecutor
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredPowerPointLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from datetime import datetime

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë²¼ë½ì¹˜ê¸° ë„ìš°ë¯¸",
    page_icon="â³",
)

# Streamlit ì•± ì„¤ì •
def main():
    st.title("â³ ëŒ€í•™ìƒ ë²¼ë½ì¹˜ê¸° ë„ìš°ë¯¸")

    # ìƒíƒœ ì´ˆê¸°í™”
    if "uploaded_text" not in st.session_state:
        st.session_state.uploaded_text = None
    if "summary" not in st.session_state:
        st.session_state.summary = None
    if "roadmap" not in st.session_state:
        st.session_state.roadmap = None
    if "quiz" not in st.session_state:
        st.session_state.quiz = None

    # ì‚¬ì´ë“œë°” UI ì„¤ì •
    with st.sidebar:
        uploaded_files = st.file_uploader("ğŸ“„ ê°•ì˜ ìë£Œ ì—…ë¡œë“œ", type=["pdf", "docx", "pptx"], accept_multiple_files=True)
        openai_api_key = st.text_input("ğŸ”‘ OpenAI API í‚¤", type="password")
        exam_date = st.date_input("ğŸ“… ì‹œí—˜ ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”")
        process_button = st.button("ğŸš€ ë²¼ë½ì¹˜ê¸° ì‹œì‘í•˜ê¸°")

        # ì²´í¬ë°•ìŠ¤ ì„¤ì •
        create_summary = st.checkbox("í•µì‹¬ ìš”ì•½ ìƒì„±", value=True)
        create_roadmap = st.checkbox("ê³µë¶€ ë¡œë“œë§µ ìƒì„±", value=True)
        create_quiz = st.checkbox("ì˜ˆìƒ ë¬¸ì œ ìƒì„±", value=True)

    if process_button:
        if not openai_api_key:
            st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        if not uploaded_files:
            st.warning("ê°•ì˜ ìë£Œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            return
        if not exam_date:
            st.warning("ì‹œí—˜ ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")
            return

        # ì‹œí—˜ê¹Œì§€ ë‚¨ì€ ê¸°ê°„ ê³„ì‚°
        today = datetime.now().date()
        days_left = (exam_date - today).days
        if days_left <= 0:
            st.warning("ì‹œí—˜ ë‚ ì§œëŠ” ì˜¤ëŠ˜ ì´í›„ì—¬ì•¼ í•©ë‹ˆë‹¤!")
            return

        # íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        st.session_state.uploaded_text = extract_text_from_files(uploaded_files)
        text_chunks = split_text_into_chunks(st.session_state.uploaded_text)
        vectorstore = create_vectorstore(text_chunks, openai_api_key)
        llm = ChatOpenAI(openai_api_key=openai_api_key, model_name="gpt-4")

        if create_summary:
            st.session_state.summary = summarize_text(text_chunks, llm)

        if create_roadmap and st.session_state.summary:
            st.session_state.roadmap = create_study_roadmap(st.session_state.summary, llm, days_left)

        if create_quiz and st.session_state.summary:
            st.session_state.quiz = generate_quiz_questions(st.session_state.summary, llm)

    if st.session_state.summary:
        st.subheader("ğŸ“Œ í•µì‹¬ ìš”ì•½")
        st.markdown(st.session_state.summary)

    if st.session_state.roadmap:
        st.subheader("ğŸ“‹ ê³µë¶€ ë¡œë“œë§µ")
        st.markdown(st.session_state.roadmap)

    if st.session_state.quiz:
        st.subheader("â“ ì˜ˆìƒ ë¬¸ì œ")
        st.markdown(st.session_state.quiz)


# íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_files(files):
    doc_list = []
    for file in files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".tmp") as tmp_file:
            tmp_file.write(file.read())
            temp_file_path = tmp_file.name

        if file.name.endswith(".pdf"):
            loader = PyPDFLoader(temp_file_path)
        elif file.name.endswith(".docx"):
            loader = Docx2txtLoader(temp_file_path)
        elif file.name.endswith(".pptx"):
            loader = UnstructuredPowerPointLoader(temp_file_path)
        else:
            st.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file.name}")
            continue

        documents = loader.load_and_split()
        doc_list.extend(documents)
        os.remove(temp_file_path)
    return doc_list

# í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• 
def split_text_into_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,  # ì²­í¬ í¬ê¸° ì¡°ì •
        chunk_overlap=500  # ì¤‘ë³µ ì„¤ì •
    )
    return text_splitter.split_documents(text)

# ë²¡í„° ì €ì¥ì†Œ ìƒì„± (OpenAI ì„ë² ë”© ì‚¬ìš©)
def create_vectorstore(text_chunks, openai_api_key):
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    return FAISS.from_documents(text_chunks, embeddings)

# í…ìŠ¤íŠ¸ ìš”ì•½ (í”„ë¡¬í”„íŠ¸ ê°œì„  ë° ë³‘ë ¬ ì²˜ë¦¬)
def summarize_text(text_chunks, llm, max_summary_length=2000):
    def process_chunk(chunk):
        text = chunk.page_content
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ í•œêµ­ ëŒ€í•™ìƒì˜ ì‹œí—˜ ì¤€ë¹„ë¥¼ ë•ëŠ” ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(content=f"""
            ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•™êµ ì‹œí—˜ ì¤€ë¹„ë¥¼ ìœ„í•´ ìš”ì•½í•´ì£¼ì„¸ìš”:
            1. í•µì‹¬ ê°œë…, ì •ì˜, ì£¼ìš” ì´ë¡  ë° ì°¨ì´ì ì„ ê°„ê²°í•˜ê²Œ í¬í•¨í•˜ì„¸ìš”.
            2. ë¶ˆí•„ìš”í•œ ë°°ê²½ ì •ë³´ëŠ” ìƒëµí•˜ê³  ì‹œí—˜ì— ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ë†’ì€ ë‚´ìš©ì„ ê°•ì¡°í•˜ì„¸ìš”.
            3. ê°„ë‹¨í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ì´í•´í•˜ê¸° ì‰½ë„ë¡ ì •ë¦¬í•˜ì„¸ìš”.

            í…ìŠ¤íŠ¸:
            {text}
            """)
        ]
        response = llm(messages)
        return response.content

    # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì²­í¬ë³„ ìš”ì•½ ìƒì„±
    with ThreadPoolExecutor(max_workers=4) as executor:
        summaries = list(executor.map(process_chunk, text_chunks))

    # ìš”ì•½ ê²°ê³¼ ê²°í•©
    combined_summary = "\n".join(summaries)
    return combined_summary[:max_summary_length] + "..." if len(combined_summary) > max_summary_length else combined_summary

# ê³µë¶€ ë¡œë“œë§µ ìƒì„±
def create_study_roadmap(summary, llm, days_left):
    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ëŒ€í•™ìƒì´ ì‹œí—˜ ì¤€ë¹„ë¥¼ ì˜ í•  ìˆ˜ ìˆë„ë¡ ë„ì›€ì„ ì£¼ëŠ” ë¡œë“œë§µ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
        HumanMessage(content=f"""
        ë‹¤ìŒ ìš”ì•½ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ {days_left}ì¼ ë™ì•ˆ íš¨ê³¼ì ìœ¼ë¡œ ê³µë¶€í•  ìˆ˜ ìˆëŠ” ë¡œë“œë§µì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
        1. ë‚¨ì€ ì¼ìˆ˜ë¥¼ ê³ ë ¤í•˜ì—¬ ë§¤ì¼ ê³µë¶€í•  ì£¼ì œì™€ ë¶„ëŸ‰ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
        2. ì¤‘ìš”í•œ ê°œë…, ì´ë¡ , ì°¨ì´ì ì„ í•™ìŠµí•˜ëŠ” ë° ìš°ì„ ìˆœìœ„ë¥¼ ë‘ì„¸ìš”.
        3. ë³µìŠµê³¼ ì˜ˆìƒ ë¬¸ì œ í’€ì´ë¥¼ í¬í•¨í•œ íš¨ìœ¨ì ì¸ í•™ìŠµ ê³„íšì„ ì œì‹œí•˜ì„¸ìš”.

        ìš”ì•½ë¬¸:
        {summary}
        """)
    ]
    response = llm(messages)
    return response.content

# ì˜ˆìƒ ë¬¸ì œ ìƒì„±
def generate_quiz_questions(summary, llm):
    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ì˜ˆìƒ ë¬¸ì œë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
        HumanMessage(content=f"""
        ë‹¤ìŒ ìš”ì•½ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ í•™êµ ì‹œí—˜ì— ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ë†’ì€ 10ê°œ ì´ìƒì˜ ì˜ˆìƒ ë¬¸ì œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
        1. ì‹œí—˜ì—ì„œ ì¤‘ìš”ë„ê°€ ë†’ì€ ê°œë…ê³¼ ì´ë¡ ì— ê¸°ë°˜í•œ ë¬¸ì œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        2. ë¬¸ì œë§ˆë‹¤ ì¤‘ìš”ë„ë¥¼ 'ë†’ìŒ', 'ì¤‘ê°„', 'ë‚®ìŒ'ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”.
        3. ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.

        ìš”ì•½ë¬¸:
        {summary}
        """)
    ]
    response = llm(messages)
    return response.content

if __name__ == "__main__":
    main()
