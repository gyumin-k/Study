import streamlit as st
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredPowerPointLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains.summarize import load_summarize_chain
from langchain.prompts import PromptTemplate
from datetime import datetime, timedelta
import time


# Streamlit ì•± ì„¤ì •
def main():
    st.set_page_config(
        page_title="ë²¼ë½ì¹˜ê¸° ë„ìš°ë¯¸",
        page_icon="â³",
    )
    st.title("â³ ëŒ€í•™ìƒ ë²¼ë½ì¹˜ê¸° ë„ìš°ë¯¸")

    if "uploaded_text" not in st.session_state:
        st.session_state.uploaded_text = None

    if "roadmap" not in st.session_state:
        st.session_state.roadmap = None

    if "quiz" not in st.session_state:
        st.session_state.quiz = None

    with st.sidebar:
        uploaded_files = st.file_uploader("ğŸ“„ ê°•ì˜ ìë£Œ ì—…ë¡œë“œ", type=["pdf", "docx", "pptx"], accept_multiple_files=True)
        openai_api_key = st.text_input("ğŸ”‘ OpenAI API í‚¤", type="password")
        exam_date = st.date_input("ğŸ“… ì‹œí—˜ ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”")
        process_button = st.button("ğŸš€ ë²¼ë½ì¹˜ê¸° ì‹œì‘í•˜ê¸°")

    if process_button:
        if not openai_api_key:
            st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        if not uploaded_files:
            st.warning("ê°•ì˜ ìë£Œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            return
        if not exam_date:
            st.warning("ì‹œí—˜ ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")
            return

        # ì‹œí—˜ê¹Œì§€ ë‚¨ì€ ê¸°ê°„ ê³„ì‚°
        days_left = (exam_date - datetime.now().date()).days
        if days_left <= 0:
            st.warning("ì‹œí—˜ ë‚ ì§œëŠ” ì˜¤ëŠ˜ë³´ë‹¤ ì´í›„ì—¬ì•¼ í•©ë‹ˆë‹¤!")
            return

        # ì—…ë¡œë“œí•œ íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        st.session_state.uploaded_text = extract_text_from_files(uploaded_files)

        # ë²¡í„° ì €ì¥ì†Œ ë° ìš”ì•½ ìƒì„±
        text_chunks = split_text_into_chunks(st.session_state.uploaded_text)
        vectorstore = create_vectorstore(text_chunks)
        llm = ChatOpenAI(openai_api_key=openai_api_key, model_name="gpt-3.5-turbo")

        # í•µì‹¬ ìš”ì•½ ìƒì„±
        st.session_state.summary = summarize_text(text_chunks, llm)

        # ê³µë¶€ ë¡œë“œë§µ ìƒì„±
        st.session_state.roadmap = create_study_roadmap(st.session_state.summary, llm, days_left)

        # ì˜ˆìƒ ë¬¸ì œ ìƒì„±
        st.session_state.quiz = generate_quiz_questions(st.session_state.summary, llm)

    if st.session_state.uploaded_text:
        st.subheader("ğŸ“Œ í•µì‹¬ ìš”ì•½")
        st.markdown(st.session_state.summary)

        st.subheader("ğŸ“‹ ê³µë¶€ ë¡œë“œë§µ")
        st.markdown(st.session_state.roadmap)

        st.subheader("â“ ì˜ˆìƒ ë¬¸ì œ")
        st.markdown(st.session_state.quiz)


# íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_from_files(files):
    doc_list = []
    for file in files:
        if file.name.endswith(".pdf"):
            loader = PyPDFLoader(file)
        elif file.name.endswith(".docx"):
            loader = Docx2txtLoader(file)
        elif file.name.endswith(".pptx"):
            loader = UnstructuredPowerPointLoader(file)
        documents = loader.load_and_split()
        doc_list.extend(documents)
    return doc_list


# í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• 
def split_text_into_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    return text_splitter.split_documents(text)


# ë²¡í„° ì €ì¥ì†Œ ìƒì„±
def create_vectorstore(text_chunks):
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    return FAISS.from_documents(text_chunks, embeddings)


# í…ìŠ¤íŠ¸ ìš”ì•½
def summarize_text(text_chunks, llm):
    # Summarization with a PromptTemplate
    summarization_prompt = PromptTemplate(
        input_variables=["text"],
        template="Summarize the following text:\n\n{text}"
    )
    text = " ".join([chunk.page_content for chunk in text_chunks])
    response = llm(summarization_prompt.format(text=text))
    return response["text"]


# ê³µë¶€ ë¡œë“œë§µ ìƒì„± (ì‹œí—˜ì¼ê¹Œì§€ ë‚¨ì€ ê¸°ê°„ì„ ê³ ë ¤)
def create_study_roadmap(summary, llm, days_left):
    roadmap_prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ {days_left}ì¼ ë™ì•ˆ íš¨ê³¼ì ìœ¼ë¡œ ê³µë¶€í•  ê³„íšì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:
    - ì¤‘ìš” ê°œë…ì„ ë¨¼ì € í•™ìŠµí•˜ë„ë¡ ê³„íší•˜ì„¸ìš”.
    - ë§¤ì¼ í•™ìŠµëŸ‰ì„ ê· ë“±í•˜ê²Œ ë‚˜ëˆ„ë˜, ë³µìŠµ ì‹œê°„ì„ í¬í•¨í•˜ì„¸ìš”.
    - ë§ˆì§€ë§‰ ë‚ ì€ ë³µìŠµ ë° ì˜ˆìƒ ë¬¸ì œ í’€ì´ì— ì§‘ì¤‘í•˜ì„¸ìš”.
    - í•™ìŠµ ê³„íšì„ í•˜ë£¨ ë‹¨ìœ„ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    {summary}
    """
    return llm(roadmap_prompt)["text"]


# ì˜ˆìƒ ë¬¸ì œ ìƒì„±
def generate_quiz_questions(summary, llm):
    quiz_prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œí—˜ì— ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” 5ê°œì˜ ì˜ˆìƒ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”:
    {summary}
    - ê° ì§ˆë¬¸ì€ êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ ì‘ì„±
    """
    return llm(quiz_prompt)["text"]


if __name__ == "__main__":
    main()
